# Whisper-Based Multilingual ASR for Indic Languages

**Paper:** *Whisper-Based Multilingual ASR for Indic Languages*  
**Conference:** Pattern Recognition and Machine Intelligence (**PReMI 2025**)  
**Venue:** IIT Delhi  
**Status:** Accepted

**Website** : *https://iamshreeji-copy2.github.io/Evaluating_Whisper/*
---

## Abstract

Automatic Speech Recognition (ASR) for Indic languages remains a challenging problem due to linguistic diversity, script variations, and the limited availability of labeled speech data for many languages. In this work, we present a comprehensive evaluation of OpenAI’s Whisper multilingual ASR models across **15 Indic languages**, including several **low-resource and underrepresented languages**.

Our study analyzes language-wise ASR performance using standardized evaluation metrics and highlights both the strengths and limitations of large-scale multilingual pretraining for Indic speech recognition.

This research was conducted at the **Speech Research Lab, DAIICT**.

---

## Languages Evaluated

The following Indic languages are included in the evaluation:

Assamese, Bengali, Gujarati, Hindi, Kannada, Malayalam, Nepali, Punjabi, Sanskrit, Tamil, Telugu, Dogri, Maithili, Manipuri, and Rajasthani.

---

## Dataset Description

- Curated multilingual speech dataset  
- **Gender-balanced** samples (male and female speakers)  
- Standardized preprocessing across all languages  
- Designed to enable fair, language-wise ASR comparison  

**Data Availability:**  
https://www.iitm.ac.in/donlab/indictts/database

---

## Methodology

- Evaluation of multiple variants of **OpenAI Whisper** models  
- Language-wise ASR benchmarking  
- Evaluation metrics:
  - **Word Error Rate (WER)**
  - **Character Error Rate (CER)**
- Comparative analysis across high-resource and low-resource Indic languages

---

## Key Observations

- Whisper models perform strongly on several high-resource Indic languages  
- Noticeable performance degradation for low-resource and underrepresented languages  
- Certain languages remain challenging even for large pretrained multilingual models  
- Highlights the need for more **inclusive and language-aware ASR systems**

---

## Authors
	•	Saroj Pandit
	•	Ravindrakumar M. Purohit
	•	Prof. Hemant A. Patil

	(202418048, 202321002, hemant_patli)@dau.ac.in

Speech Research Lab, DAIICT

⸻

Acknowledgements

The authors thank PReMI 2025 and IIT Delhi for providing an excellent platform for presenting and discussing this work. We also acknowledge the support of the Speech Research Lab, DAIICT.
